{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#import os\n",
    "#os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "#os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import bct\n",
    "import sys\n",
    "sys.path.append(home + '/workspace/networkqit')\n",
    "import networkqit as nq\n",
    "from networkqit.graphtheory.models.MEModels import CWTECM, UBCM, UWCM, UECM3\n",
    "from networkqit.utils.visualization import plot_mle\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresh_none = pickle.load(open(home+'/workspace/entropy_analysis/notebooks/data_forcellini_thresh_none.pkl','rb'))['forcellini']\n",
    "G = df_thresh_none[(df_thresh_none['motion']=='L') & (df_thresh_none['passages']==1)]['A'].values[0][0:64,0:64]\n",
    "G = bct.threshold_proportional(G,0.20)*5\n",
    "t = G[np.nonzero(G)].min()\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = G\n",
    "A = (G>t).astype(float)\n",
    "k = A.sum(axis=0)\n",
    "s = G.sum(axis=0)\n",
    "print('threshold=',t)\n",
    "\n",
    "M = CWTECM(N=len(G), threshold=t)\n",
    "x0 = (np.concatenate([k,s])) / max(np.max(k),np.max(s))\n",
    "#x0 = sol['x']\n",
    "# # Optimize by L-BFGS-B\n",
    "opt = nq.MLEOptimizer(G, x0=x0, model=M)\n",
    "import time\n",
    "start = time.time()\n",
    "sol = opt.run(model=M, verbose=2, maxiter=5000, ftol=1E-9, gtol=1E-9, method='MLE')\n",
    "print('Optimization elapsed time = ', time.time()-start, ' seconds ')\n",
    "print('Loglikelihood = ', M.loglikelihood(G,sol['x']))\n",
    "\n",
    "pij = M.expected_adjacency(sol['x'])\n",
    "wij = M.expected_weighted_adjacency(sol['x'])\n",
    "plot_mle(G,pij,wij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "np.random.seed(0)\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot((G>0).sum(axis=0), (M.sample_adjacency(sol['x'],batch_size=1000,with_grads=False)>0).mean(0).sum(axis=0),'b.')\n",
    "plt.plot([0,(G>0).sum(axis=0).max()],[0,(G>0).sum(axis=0).max()],'-k')\n",
    "plt.grid()\n",
    "plt.title('with no grads - degrees')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(G.sum(axis=0), M.sample_adjacency(sol['x'],batch_size=1000,with_grads=False).mean(axis=0).sum(axis=0),'r.')\n",
    "plt.plot([0,G.sum(axis=0).max()],[0,G.sum(axis=0).max()],'-k')\n",
    "plt.grid()\n",
    "plt.yticks(np.arange(0,G.sum(axis=0).max(),5))\n",
    "plt.title('with no grads - strenght')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot((G>0).sum(axis=0), (M.sample_adjacency(sol['x'],batch_size=1000,with_grads=True)>0).mean(0).sum(axis=0),'b.')\n",
    "plt.plot([0,(G>0).sum(axis=0).max()],[0,(G>0).sum(axis=0).max()],'-k')\n",
    "plt.grid()\n",
    "plt.title('with grads - degrees')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(G.sum(axis=0), M.sample_adjacency(sol['x'],batch_size=1000,with_grads=True).mean(axis=0).sum(axis=0),'r.')\n",
    "plt.plot([0,G.sum(axis=0).max()],[0,G.sum(axis=0).max()],'-k')\n",
    "plt.grid()\n",
    "plt.title('with grads - strength')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresh_none = pickle.load(open(home+'/workspace/entropy_analysis/notebooks/data_forcellini_thresh_none.pkl','rb'))['forcellini']\n",
    "\n",
    "def optimize_benchmark():\n",
    "    from itertools import product\n",
    "    likelihood = []\n",
    "    #for threshold, motion, passages in product(np.linspace(0.025,0.25,10),['L','M','H'],[ 5, 27,  8, 24,  9,  0,  1, 85,  6]):\n",
    "    for threshold, motion, passages in product(np.linspace(0.025,0.05,1),['L','M','H'],[9]):\n",
    "        G = df_thresh_none[(df_thresh_none['motion']==motion) & (df_thresh_none['passages']==passages)]['A'].values[0]\n",
    "        G = bct.threshold_proportional(G,threshold)\n",
    "        t = G[np.nonzero(G)].min()\n",
    "        k = (G>0).sum(axis=0)\n",
    "        s = (G).sum(axis=0)\n",
    "        M = CWTECM(N=len(G), threshold=t)\n",
    "        x0 = (np.concatenate([k,s])) / max(np.max(k),np.max(s))\n",
    "        # # Optimize by L-BFGS-B\n",
    "        opt = nq.MLEOptimizer(G, x0=x0, model=M)\n",
    "        import time\n",
    "        start = time.time()\n",
    "        sol = opt.run(model = M, verbose=1, maxiter=100, ftol=1E-9, gtol=1E-6, method='MLE')\n",
    "        likelihood.append(M.loglikelihood(G,sol['x']))\n",
    "        print('Loglikelihood = ', M.loglikelihood(G,sol['x']), '\\tOptimization elapsed time = ', time.time()-start, ' seconds ')\n",
    "    return zip(likelihood,product(np.linspace(0.025,0.25,10),['L','M','H'],[ 5, 27,  8, 24,  9,  0,  1, 85,  6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=list(optimize_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import grad\n",
    "h = grad(lambda z : M.sample_adjacency(z,with_grads=True).sum())\n",
    "gr = h(sol['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.round(G[0:128,0:128]*50)\n",
    "A = (G>t).astype(float)\n",
    "k = A.sum(axis=0)\n",
    "s = G.sum(axis=0)\n",
    "print('threshold=',t)\n",
    "\n",
    "M = UECM3(N=len(G), threshold=t)\n",
    "x0 = (np.concatenate([k,s])) / max(np.max(k),np.max(s))\n",
    "#x0 = sol['x']\n",
    "# # Optimize by L-BFGS-B\n",
    "opt = nq.MLEOptimizer(G, x0=x0, model=M)\n",
    "import time\n",
    "start = time.time()\n",
    "sol = opt.run(model=M, verbose=2, maxiter=1000, ftol=1E-9, gtol=1E-6, method='MLE')\n",
    "print('Optimization elapsed time = ', time.time()-start, ' seconds ')\n",
    "print('Loglikelihood = ', M.loglikelihood(G,sol['x']))\n",
    "\n",
    "pij = M.expected_adjacency(sol['x'])\n",
    "wij = M.expected_weighted_adjacency(sol['x'])\n",
    "plot_mle(G,pij,wij)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
