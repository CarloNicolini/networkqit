{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/carlo/workspace/networkqit/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import networkqit as nq\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from networkqit.utils.visualization import step_callback, plot_spectral_entropy\n",
    "from networkqit import graph_laplacian\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "import warnings\n",
    "from drawnow import drawnow, figure\n",
    "# Set seaborn as matplotlib backend style\n",
    "sns.set()\n",
    "from os.path import expanduser\n",
    "from bct import threshold_proportional, threshold_absolute\n",
    "home = expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the methods to create weighted correlation networks from factor model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_model(ci,T,eta,mu):\n",
    "    N = len(ci) # number of nodes, length of membership vector\n",
    "    # Initialize the observations vector a TxN matrix of NaNs\n",
    "    Y = np.ones([T,N])*np.nan\n",
    "    \n",
    "    # Fill the identical observations in the maximally correlated subsets\n",
    "    for c in np.unique(ci):\n",
    "        i = np.where(ci==c)[0]\n",
    "        Y[:,i] = np.kron(np.ones((1,(ci==c).sum())),np.random.randn(T,1))\n",
    "\n",
    "    # Add local noise beta on each time-series\n",
    "    Y += eta*np.random.randn(T,N)\n",
    "        \n",
    "    # Add global signal mu that correlates globally each time series\n",
    "    Y += mu*np.kron(np.ones((1,N)),np.random.randn(T,1))\n",
    "\n",
    "    from scipy.stats import zscore\n",
    "    Y = zscore(Y)\n",
    "    C = np.corrcoef(Y.T)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brain_network(ci, T=150, local_noise=2, global_noise=4, gamma=10, density=0.1):\n",
    "    C = np.triu(factor_model(ci,T,local_noise,global_noise),1)\n",
    "    C += C.T\n",
    "    C = C**gamma # soft thresholding\n",
    "    C/=C.max()\n",
    "    C = np.arctanh(C)\n",
    "    C[np.isinf(C)]=0\n",
    "    C = threshold_proportional(C,density) # keep a specific percentage of links\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_membership(membership):\n",
    "    \"\"\"\n",
    "    This function has the membership as input and output the membership\n",
    "    where the communities number are ordered by the number of nodes in that community\n",
    "    \"\"\"\n",
    "    ds = {}\n",
    "    for u, v in enumerate(membership):\n",
    "        if v not in ds.keys():\n",
    "            ds[v] = []\n",
    "        ds[v].append(u)\n",
    "\n",
    "    S = dict(\n",
    "        zip(range(0, len(ds)), sorted(ds.values(), key=len, reverse=True)))\n",
    "\n",
    "    M = {}\n",
    "\n",
    "    for u, vl in S.items():\n",
    "        for v in vl:\n",
    "            M[v] = u\n",
    "    return list(M.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=2,nrows=1,figsize=(20,8))\n",
    "A = brain_network(ci,T=100,local_noise=2.5, global_noise=4, gamma=1,density=1)\n",
    "plt.suptitle('Networks from factor model local noise $\\eta=2.2$ global noise $\\mu=4$')\n",
    "h=ax[0].imshow(A,cmap='viridis')\n",
    "ax[0].grid(False)\n",
    "ax[0].set_title('Adjacency |E|=' + str(len(A.nonzero()[0])/2))\n",
    "plt.colorbar(h,ax=ax[0])\n",
    "ax[1].hist(A.flatten()[np.flatnonzero(A)],500,alpha=0.8)\n",
    "ax[1].grid(True)\n",
    "ax[1].set_title('Edge weights histogram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "W=loadmat('/home/carlo/workspace/communityalg/data/GroupAverage_rsfMRI_matrix_unthr.mat')['RS_unthr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = brain_network(ci=sorted(np.random.randint(0,6,638)),T=150,local_noise=1.5,global_noise=4,gamma=5,density=0.6)\n",
    "plt.hist(A.sum(axis=0),80,alpha=0.5,color='r')\n",
    "plt.hist(W.sum(axis=0),80,alpha=0.5,color='b')\n",
    "plt.legend(['Synthetic','Crossley'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bct\n",
    "import sys\n",
    "ci = bct.community_louvain(bct.threshold_absolute(W,0.6))\n",
    "ci = reindex_membership(ci[0])\n",
    "[bounds,ixes] = bct.grid_communities(np.array(ci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T,local_noise,global_noise,factor=200,2.5,1.5,0.8\n",
    "\n",
    "A = brain_network(ci=ci, T=200, local_noise=local_noise, global_noise=global_noise, gamma=1, density=1)*factor\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3,nrows=1,figsize=(24,6))\n",
    "#plt.suptitle('Networks from factor model local noise $\\eta=2.2$ global noise $\\mu=4$')\n",
    "##### plot 0\n",
    "h0 = ax[0].imshow(W[np.ix_(ixes,ixes)],cmap='viridis')\n",
    "ax[0].grid(False)\n",
    "ax[0].set_title('Crossley')\n",
    "#### plot 1\n",
    "h1 = ax[1].imshow(A[np.ix_(ixes,ixes)],cmap='viridis')\n",
    "ax[1].grid(False)\n",
    "ax[1].set_title('Synthetic')\n",
    "##### plot 2\n",
    "ax[2].hist(W.ravel(),200,alpha=0.5,color='b')\n",
    "ax[2].grid(True)\n",
    "ax[2].set_title('Edge weights histogram Synthetic')\n",
    "ax[2].hist(A.flatten(),200,alpha=0.5,color='r')\n",
    "plt.colorbar(h0,ax=ax[0])\n",
    "plt.colorbar(h1,ax=ax[1])\n",
    "plt.legend(['Crossley','Synthetic'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import eigvalsh\n",
    "entropy(eigvalsh(W),eigvalsh(brain_network(ci=ci, T=T, local_noise=local_noise, global_noise=global_noise, gamma=1, density=1)*factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "def klhistdiv(ci,T, local_noise, global_noise, gamma, density, factor, empirical_hist):\n",
    "    A = brain_network(ci, T, local_noise, global_noise, gamma, density)*factor\n",
    "    w = A.flatten()[np.flatnonzero(W.flatten())]\n",
    "    weights_hist, weights_bins = np.histogram(w,500,density=False)\n",
    "    plt.plot(empirical_hist)\n",
    "    plt.plot(weights_hist)\n",
    "    dkl = entropy(empirical_hist/empirical_hist.sum(), weights_hist/weights_hist.sum())\n",
    "    print('\\r',T, local_noise, global_noise, gamma, density, factor,'-->',dkl,end='')\n",
    "    return dkl\n",
    "\n",
    "weights = W.flatten()[np.flatnonzero(W.flatten())]\n",
    "weights_hist, weights_bins = np.histogram(weights, 500, density=False)\n",
    "\n",
    "klhistdiv(ci,T,local_noise=local_noise,global_noise=global_noise,gamma=1,factor=factor,density=1,empirical_hist=weights_hist)\n",
    " #brain_network(ci=ci, T=100, local_noise=1.9, global_noise=1, gamma=1, density=1)*0.8\n",
    "#ranges = (slice(1,4,0.5), slice(1,6,0.5))\n",
    "#T = 150\n",
    "#res = scipy.optimize.brute(lambda x : klhistdiv(ci, T, x[0], x[1], 1, 1, 1, weights_hist), ranges=ranges, full_output=False, finish=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percolation_analysis(W,thresholds):\n",
    "    giant = []\n",
    "    for t in thresholds:\n",
    "        Wt = threshold_absolute(W,t)\n",
    "        memb, sizes = bct.get_components(Wt)\n",
    "        giant.append(sizes.max())\n",
    "    return giant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt=100\n",
    "giantW = percolation_analysis(W,np.linspace(0.0,W.max(),nt))\n",
    "giantA = percolation_analysis(A,np.linspace(0.0,A.max(),nt))\n",
    "plt.figure(figsize=(24,8))\n",
    "plt.plot(np.linspace(0.0,W.max(),nt),giantW)\n",
    "plt.plot(np.linspace(0.0,W.max(),nt),giantA)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Giant component')\n",
    "plt.title('Percolation analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study the spectral entropy as function of internal symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def asymmetric_clique(N1,N2):\n",
    "    G1 = nx.complete_graph(N1)\n",
    "    G2 = nx.complete_graph(N2)\n",
    "    G = nx.disjoint_union(G1,G2)\n",
    "    if not nx.is_empty(G1):\n",
    "        n1last = (list(G1.nodes())[-1])\n",
    "        n2last = (list(G2.nodes())[-1])\n",
    "        G.add_edge(n1last,n1last+1)\n",
    "    return nx.to_numpy_array(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=60\n",
    "beta_range = np.logspace(-3,3,50)\n",
    "vals = range(0,N+2,5)\n",
    "cmap = sns.color_palette('viridis',len(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.semilogx(1/beta_range, [nq.compute_vonneumann_entropy(L=nq.graph_laplacian(asymmetric_clique(50,50)),beta=beta) for beta in beta_range])\n",
    "plt.figure(figsize=(20,8))\n",
    "for i,j in enumerate(vals):\n",
    "    plt.semilogx(1/beta_range, [nq.compute_vonneumann_entropy(L=nq.graph_laplacian(asymmetric_clique(N-j,N+j)),beta=beta) for beta in beta_range],color=cmap[i])\n",
    "plt.legend(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study the derivatives of spectral entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "for i,j in enumerate(vals):\n",
    "    plt.semilogx(1/beta_range, [nq.compute_vonneumann_entropy_beta_deriv(L=nq.graph_laplacian(asymmetric_clique(N-j,N+j)),beta=beta) for beta in beta_range],color=cmap[i])\n",
    "plt.legend(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the spectral entropy as function of the threshold $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_range=np.logspace(-3, 1.5, 100)\n",
    "cmap = sns.color_palette('viridis',5)\n",
    "all_thresh = np.linspace(0,0.25,5)\n",
    "plt.figure(figsize=(20,8))\n",
    "for i,t in enumerate(all_thresh):\n",
    "    plt.semilogx(1/beta_range,np.clip([nq.SpectralDivergence(Lobs=graph_laplacian(threshold_absolute(A,t)),Lmodel=graph_laplacian(threshold_absolute(W,t)),beta=b).rel_entropy \n",
    "                                   for b in beta_range ],0,20),color=cmap[i])\n",
    "plt.xlabel('$1/\\\\beta$')\n",
    "plt.legend(all_thresh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot until one connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percolation_threshold(A):\n",
    "    w = np.unique((A*(A>0).astype(float)).flatten())\n",
    "    iw = range(0,len(w))\n",
    "    i_perc = np.where(np.array([len(get_components(threshold_absolute(A,t))[1]) for t in w]) > 1)\n",
    "    return i_perc[0][0], w[i_perc][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_perc,w_perc = percolation_threshold(A)\n",
    "print(i_perc,w_perc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
