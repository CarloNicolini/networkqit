{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import networkqit as nq\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "import scipy\n",
    "# import some dependencies\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_array(nx.karate_club_graph())\n",
    "L = nq.graph_laplacian(A)\n",
    "beta_range=np.logspace(1,-4,5)\n",
    "N=len(A)\n",
    "print(nx.density(nx.karate_club_graph()))\n",
    "M = nq.ErdosRenyi(N=N)\n",
    "def sampling_er(p):\n",
    "    return nx.to_numpy_array(nx.erdos_renyi_graph(N,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=np.random.random(1,)\n",
    "#x0=np.array([0.2,])\n",
    "solver = nq.Adam(A=A,x0=x0,beta_range=np.logspace(3,-3,25))\n",
    "print('Starting from',solver.x0)\n",
    "solver.setup(expected_adj_fun = M, adj_sampling_fun = sampling_er, expected_laplacian_grad=M.expected_laplacian_grad, step_callback = lambda beta,p : print('\\rbeta=',beta,'p=',p[0],end=''))\n",
    "sol,all_x = solver.run(max_iters=200,alpha=1E-3,num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=np.random.random(1,)\n",
    "#x0=np.array([0.2,])\n",
    "solver = nq.StochasticGradientDescent(A=A,x0=x0,beta_range=np.logspace(1,-1,25))\n",
    "print('Starting from',solver.x0)\n",
    "solver.setup(expected_adj_fun = M, adj_sampling_fun = sampling_er, expected_laplacian_grad=M.expected_laplacian_grad, step_callback = lambda beta,p : print('\\rbeta=',beta,'p=',p[0],end=''))\n",
    "sol,all_x = solver.run(clip_gradients=(-1000,1000),max_iters=200,eta=1E-3,num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array([nx.density(nx.karate_club_graph())]*len(all_x)))\n",
    "plt.plot(all_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(sol)\n",
    "\n",
    "#df.plot(x='T',y='rel_entropy',logx=True,logy=True,figsize=(12,12))\n",
    "plt.semilogx(np.array(df['T']),np.array([nx.density(nx.karate_club_graph())]*len(df)))\n",
    "#plt.semilogx(np.array(df['T']),[x[0] for x in df['x']])\n",
    "#plt.xlabel('1/beta')\n",
    "#plt.legend(['$E[S(\\\\rho,\\\\sigma)]$','$p^*$','$\\tilde{p}$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = nq.StochasticGradientDescent(A=A,x0=np.random.random(1,),beta_range=beta_range,clip=(-1,1))\n",
    "solver.setup(expected_adj_fun = M, adj_sampling_fun = sampling_er, expected_laplacian_grad=M.expected_laplacian_grad, step_callback = lambda beta,p: print('\\rbeta=',beta,'p=',p,end=''))\n",
    "sol = solver.run(clip_gradients=(-1,1),num_iters=1000,eta=1E-3,num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import eigvalsh\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ER(n,p):\n",
    "    return nq.graph_laplacian(nx.to_numpy_array(nx.erdos_renyi_graph(n,p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.5\n",
    "beta=1\n",
    "def average_eigs(n,p,n_samples):\n",
    "    l = np.array(np.zeros([n]))\n",
    "    for i in range(0,n_samples):\n",
    "        l += eigvalsh(ER(n,p))\n",
    "    return l/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=500\n",
    "x=[]\n",
    "samples=range(1,5,1)\n",
    "for nsamples in samples:\n",
    "    x.append(nd.Derivative(lambda x : average_eigs(N,x,nsamples))(0.5))\n",
    "    print(nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(sns.cubehelix_palette(len(samples)))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(np.array(x))\n",
    "plt.legend(list(samples))\n",
    "plt.show()\n",
    "for y in x:\n",
    "    print('<x>=',np.mean(y),'+-',np.std(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[(logsumexp(-beta*eigvalsh(nq.graph_laplacian(sampling_er(p+eps)))) - logsumexp(-beta*eigvalsh(nq.graph_laplacian(sampling_er(p)))))/eps for i in range(0,1000)]\n",
    "np.mean(x)\n",
    "np.std(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
